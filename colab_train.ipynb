{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Msingi1 - Swahili Language Model Training\n",
    "\n",
    "This notebook trains the Msingi1 model on Google Colab using GPU/TPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check if we're using GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Install required packages\n",
    "!pip install -q wandb tokenizers torch transformers datasets tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/Msingi-AI/msingi1.git\n",
    "%cd msingi1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Upload the dataset and tokenizer\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "# Create necessary directories\n",
    "!mkdir -p data tokenizer\n",
    "\n",
    "print(\"Please upload your archive.zip (dataset)...\")\n",
    "uploaded = files.upload()\n",
    "!mv *.zip data/archive.zip\n",
    "\n",
    "print(\"\\nPlease upload your tokenizer files (tokenizer.json, vocab.json, merges.txt)...\")\n",
    "uploaded = files.upload()\n",
    "!mv tokenizer.json vocab.json merges.txt tokenizer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Configure WandB (optional)\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import torch\n",
    "import os\n",
    "from src.model import Msingi1, MsingiConfig\n",
    "from src.train import train\n",
    "from src.data_processor import extract_dataset\n",
    "\n",
    "# Load dataset\n",
    "texts = extract_dataset(\"data/archive.zip\")\n",
    "print(f\"Loaded {len(texts)} texts\")\n",
    "\n",
    "# Split into train/val\n",
    "val_size = int(len(texts) * 0.1)\n",
    "train_texts = texts[val_size:]\n",
    "val_texts = texts[:val_size]\n",
    "\n",
    "# Initialize config with larger model for GPU/TPU\n",
    "config = MsingiConfig(\n",
    "    vocab_size=50000,\n",
    "    max_position_embeddings=2048,\n",
    "    hidden_size=768,\n",
    "    num_hidden_layers=12,\n",
    "    num_attention_heads=12,\n",
    "    intermediate_size=3072,\n",
    "    gradient_checkpointing=True  # Enable for memory efficiency\n",
    ")\n",
    "\n",
    "# Training parameters optimized for Colab\n",
    "train(\n",
    "    config=config,\n",
    "    train_texts=train_texts,\n",
    "    val_texts=val_texts,\n",
    "    num_epochs=10,\n",
    "    batch_size=8,  # Larger batch size for GPU\n",
    "    gradient_accumulation_steps=8,  # Still accumulate for stability\n",
    "    learning_rate=3e-4,\n",
    "    max_length=1024,\n",
    "    warmup_steps=1000,\n",
    "    save_steps=1000,\n",
    "    eval_steps=500,\n",
    "    use_wandb=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Download the trained model\n",
    "from google.colab import files\n",
    "\n",
    "# Zip the checkpoints directory\n",
    "!zip -r trained_model.zip checkpoints/\n",
    "\n",
    "# Download the zipped file\n",
    "files.download('trained_model.zip')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Msingi1 Training",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
