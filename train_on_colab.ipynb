{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Msingi-AI/msingi1/blob/main/train_on_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Msingi1: Swahili Language Model\n",
    "\n",
    "First, let's verify we have GPU access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive to save our model\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create project directory\n",
    "!mkdir -p /content/msingi1\n",
    "%cd /content/msingi1\n",
    "\n",
    "# Clone our repository\n",
    "!git clone https://github.com/Msingi-AI/msingi1.git .\n",
    "\n",
    "# Install dependencies\n",
    "%pip install torch transformers tokenizers datasets numpy tqdm wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Upload Dataset\n",
    "Upload your `archive.zip` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "print(\"Please upload your archive.zip file...\")\n",
    "uploaded = files.upload()  # Upload archive.zip here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Add Source to Python Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the current directory to Python path\n",
    "if '/content/msingi1' not in sys.path:\n",
    "    sys.path.append('/content/msingi1')\n",
    "\n",
    "# Verify imports work\n",
    "from src.data_processor import extract_dataset, get_dataset_stats\n",
    "from src.train_tokenizer import train_tokenizer\n",
    "from src.train import main as train_model\n",
    "\n",
    "print(\"✅ Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Tokenizer\n",
    "First, let's train our tokenizer on the Swahili text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train tokenizer\n",
    "tokenizer = train_tokenizer()\n",
    "\n",
    "# Save tokenizer to Drive\n",
    "!mkdir -p \"/content/drive/MyDrive/msingi1/tokenizer\"\n",
    "!cp -r tokenizer/* \"/content/drive/MyDrive/msingi1/tokenizer/\"\n",
    "print(\"✅ Tokenizer saved to Google Drive!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train Model\n",
    "Now we'll train our model using the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "train_model()\n",
    "\n",
    "# Save model checkpoints to Drive\n",
    "!mkdir -p \"/content/drive/MyDrive/msingi1/checkpoints\"\n",
    "!cp -r checkpoints/* \"/content/drive/MyDrive/msingi1/checkpoints/\"\n",
    "print(\"✅ Model checkpoints saved to Google Drive!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test the Model\n",
    "Let's test our trained model with some Swahili text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from src.model import Msingi1, MsingiConfig\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('tokenizer')\n",
    "\n",
    "# Load model config\n",
    "config = MsingiConfig(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    max_position_embeddings=512,\n",
    "    hidden_size=256,\n",
    "    num_hidden_layers=6,\n",
    "    num_attention_heads=8,\n",
    "    intermediate_size=1024,\n",
    ")\n",
    "\n",
    "# Load model from best checkpoint\n",
    "model = Msingi1(config)\n",
    "checkpoint = torch.load('checkpoints/best_model.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Test text generation\n",
    "test_text = \"Jambo, \"\n",
    "input_ids = tokenizer.encode(test_text, return_tensors='pt')\n",
    "outputs = model.generate(input_ids, max_length=50)\n",
    "generated_text = tokenizer.decode(outputs[0])\n",
    "print(f\"Generated text: {generated_text}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "train_msingi1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
